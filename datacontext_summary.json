[
  {
    "file": "./docstring_ai/__init__.py",
    "description": "Operation failed due to an API error."
  },
  {
    "file": "./docstring_ai/lib/config.py",
    "description": "Here\u2019s a comprehensive and detailed description of the provided Python file:\n\n### Overview\n\nThis Python file defines constants and logging configuration for a machine learning-based application that interacts with models and APIs. The main functionalities include specifying model parameters, handling API interactions with retry logic, organizing data storage paths, and configuring a customized logging system with colored output for better readability. The module primarily aims at improving the maintainability and usability of code related to model inference and logging.\n\n### Main Functionalities\n\n1. **Model and API Configuration**: The module manages constants related to model configurations, such as model names, token limits, retry counts, and backoff strategies for API requests.\n\n2. **Context Storage Management**: It defines constants for file paths related to data caching and context management, which optimize the performance of data retrieval operations.\n\n3. **Custom Logging Configuration**: The module implements a custom logging setup that includes colored formatting for different log levels and filtering for specific libraries to enhance the clarity and relevance of log output.\n\n### Purpose\n\nThe purpose of this Python file can be summarized as follows:\n- To provide a structured approach for constants that configure model interactions and API handling.\n- To establish a comprehensive logging solution that improves the debuggability and traceability of code execution.\n- To optimize data management and caching strategies for efficient storage and retrieval of important context-related information.\n\n### Constants and Their Descriptions\n\nThe file includes a set of constants, each playing a significant role:\n\n1. **MODEL (str)**: \n   - Defines the specific model version to be used for processing tasks. It allows flexibility in updating or changing models as required.\n\n2. **MAX_TOKENS (int)**: \n   - Establishes the maximum number of tokens allowed in a single API request. This safeguard prevents errors relating to input size, ensuring it aligns with model processing capabilities.\n\n3. **EMBEDDING_MODEL (str)**: \n   - Specifies the name of the embedding model for converting text into numerical vectors. This is essential for tasks that require embedding representations.\n\n4. **MAX_RETRIES (int)**: \n   - Indicates the maximum number of retry attempts for API requests in case of temporary failures. This is useful for handling transient errors and improving application resilience.\n\n5. **RETRY_BACKOFF (int)**: \n   - Sets the time to wait before retrying after a failed API request, allowing for controlled retries and reducing server strain.\n\n6. **CHROMA_COLLECTION_NAME (str)**: \n   - Specifies the name of the collection within ChromaDB for storing context data, facilitating organized data retrieval throughout the application lifecycle.\n\n7. **DATA_PATH (Path)**: \n   - Defines the base directory for storing data-related files, using `Path` from the `pathlib` module for better path handling.\n\n8. **CACHE_FILE_NAME (str)**: \n   - Indicates the filename used for caching purposes, contributing to performance optimization by avoiding redundant computations.\n\n9. **CONTEXT_SUMMARY_PATH (str)**: \n   - Specifies the file path for storing context summaries, which provides a means for accessing context information across different processing tasks.\n\n10. **DOCSTRING_AI_TAG**: \n   - A constant indicating the origin of the docstring that was generated by a specific tool.\n\n### Classes\n\nThe module defines the following classes:\n\n1. **ColoredFormatter(logging.Formatter)**:\n   - A custom logging formatter that adds color coding to log messages based on their severity levels. The color mapping is defined within the class, enhancing the visibility and differentiation of log levels when outputted.\n\n   **Method**: \n   - `format(self, record)`: Overrides the default format method to apply color to the log level names.\n\n2. **ExcludeLibrariesFilter(logging.Filter)**:\n   - A logging filter that excludes log messages from specified libraries. This prevents clutter in logs from libraries that may generate excessive or non-critical logging output.\n\n   **Method**: \n   - `filter(self, record)`: Returns `True` if the log record's name does not start with any specified modules in the exclusion list.\n\n3. **HTTPRequestFilter(logging.Filter)**:\n   - Another logging filter specifically designed to exclude HTTP request logs, providing a cleaner output by not including extensive HTTP interaction logs.\n\n   **Method**: \n   - `filter(self, record)`: Checks if the message contains 'HTTP Request:' and returns `False` if it does, effectively filtering it out.\n\n### Functions\n\n1. **setup_logging()**:\n   - Configures the logging for the application by initializing handlers, formatters, and levels. It creates an instance of `ColoredFormatter` and sets it to a stream handler that outputs to the console. Logging level is set to DEBUG, which captures all levels of logs, and applies filters to suppress logs from specific libraries.\n\n### Structure and Intent\n\nThe structure of the module is straightforward, with a clear separation between configuration constants, custom logging classes, and utility functions. It imports necessary libraries like `Path` from `pathlib` for filesystem path handling and `logging` alongside `colorama` for enhanced logging user experience.\n\nThe intent is to provide clarity and ease-of-use for developers interacting with the model and debugging through logging. By employing object-oriented principles in the logging configuration and defining constants in a structured manner, the module fosters better coding practices and effective application management.\n\n### Conclusion\n\nIn summary, this Python module is integral for efficiently managing configurations related to model interactions, API handling, and logging. By centralizing constants and providing a robust logging setup, it enhances the maintainability, usability, and overall performance of a machine learning application. The well-defined logging structure also aids in debugging by ensuring clear visibility into the application's operational flow."
  },
  {
    "file": "./docstring_ai/lib/chroma_utils.py",
    "description": "Here\u2019s a comprehensive and detailed description of the provided Python file:\n\n### Overview\n\nThis Python file is designed to facilitate the embedding and storage of Python files' content into a ChromaDB database. The primary functionalities focus on initializing a database client, managing collections (retrieving or creating them), embedding text documents, and storing relevant summaries and contexts for future retrieval. Moreover, it integrates OpenAI's embedding functionalities and includes extensive logging for robust error tracking and information reporting. \n\n### Main Functionalities\n\n1. **Database Initialization**: Functions to establish a connection to ChromaDB, ensuring that subsequent operations can interact with the database.\n\n2. **Collection Management**: Functions that handle the retrieval or creation of collections in ChromaDB, which organize stored data effectively.\n\n3. **Embedding and Storage**: The ability to read Python files, embed their contents, and store them within a specified ChromaDB collection for later use.\n\n4. **Context Retrieval**: A function to query the database for relevant documents based on specific criteria and return the accumulated context while adhering to token limits.\n\n5. **Storing Class Summaries**: Functions to embed summaries of classes and associate them with their respective Python files and class names in the database.\n\n6. **Error Handling and Logging**: Comprehensive logging and error handling to monitor operations and diagnose issues effectively.\n\n### Purpose\n\nThe purpose of this Python file can be summarized as follows:\n- To manage linguistic embeddings of Python file content and organize it within a ChromaDB database, providing a structured approach to access and utilize contextual information.\n- To create a seamless integration between OpenAI\u2019s embedding models and ChromaDB, facilitating efficient data retrieval in various applications such as code analysis or documentation generation.\n- To offer robust error handling and logging for developers, enabling better maintainability and usability of the code.\n\n### Function Descriptions\n\nThe file includes several key functions, each with specific responsibilities:\n\n1. **initialize_chroma() -> chromadb.Client**:\n   - Initializes and returns a ChromaDB client instance connected to a server running on localhost.\n   - **Returns**: An instance of `chromadb.Client` for database interactions.\n   - **Example**: `client = initialize_chroma()`\n\n2. **get_or_create_collection(client: chromadb.Client, collection_name: str) -> chromadb.Collection**:\n   - Retrieves an existing collection by name or creates a new one if it does not exist.\n   - **Args**:\n     - `client`: ChromaDB client instance.\n     - `collection_name`: The name of the desired collection.\n   - **Returns**: The `chromadb.Collection` instance.\n   - **Raises**: Exception if there are issues retrieving or creating the collection.\n\n3. **embed_and_store_files(collection: chromadb.Collection, python_files: List[str], tags: Dict[str, str] = {}) -> None**:\n   - Reads Python files, embeds their content, and stores the representations in the specified ChromaDB collection.\n   - **Args**:\n     - `collection`: The ChromaDB collection instance for storage.\n     - `python_files`: A list of paths to Python files.\n     - `tags`: Additional metadata to associate with stored documents.\n   - **Raises**: Exception if errors occur during file reading or storage operations.\n\n4. **get_relevant_context(collection: chromadb.Collection, classes: List[str], max_tokens: int, where: str = None) -> str**:\n   - Retrieves relevant documents from ChromaDB based on class dependencies and ensures the returned context stays within a specified token limit.\n   - **Args**:\n     - `collection`: The ChromaDB collection to query.\n     - `classes`: A list of class names to use as query text.\n     - `max_tokens`: The maximum allowed token count for the context.\n   - **Returns**: A string containing the accumulated context.\n   - **Example**: `context = get_relevant_context(collection, classes, max_tokens)`\n\n5. **store_class_summary(collection: chromadb.Collection, file_path: str, class_name: str, summary: str) -> None**:\n   - Embeds a class's summary and stores it in the ChromaDB collection with appropriate metadata.\n   - **Args**:\n     - `collection`: The ChromaDB collection where the summary will be stored.\n     - `file_path`: The path to the associated file.\n     - `class_name`: The name of the class for which the summary is stored.\n     - `summary`: The summary text to store.\n   - **Raises**: Exception if errors occur while storing the summary.\n\n### Classes\n\nNo classes are defined in this file; however, the functions leverage ChromaDB\u2019s `Client` and `Collection` types.\n\n### Structure and Intent\n\nThe structure of the module is organized around functionality, focusing on operations related to embedding and storing data. The import statements bring in necessary libraries, such as OpenAI for embeddings, ChromaDB for storage, and logging for monitoring and debugging.\n\n- **Error Handling**: Each function captures exceptions and logs them, ensuring that any issue can be traced back to its source through logging messages and stack traces. \n\n- **Modularity**: Each function serves a single purpose, making the code reusable and easier to maintain. \n\n### Conclusion\n\nIn summary, this Python module provides a comprehensive system for embedding, storing, and retrieving content from Python files using ChromaDB and OpenAI's embeddings. It incorporates robust logging and error handling, ensuring clear visibility and traceability throughout operations. This structured approach not only enhances the performance and usability of the application but also aids developers in managing and utilizing class summaries and contextual code information effectively."
  },
  {
    "file": "./docstring_ai/lib/utils.py",
    "description": "Here\u2019s a comprehensive and detailed description of the provided Python file:\n\n### Overview\n\nThis Python file serves as a utility tool primarily focused on managing Python code within a Git repository. It provides functions to check for uncommitted changes, ensure the presence of docstring headers in files, manage caching, compute hashes for file integrity, create backups, and display diffs between code versions. By integrating Git and filesystem operations, the code enhances the workflow of Python file management, particularly in the context of version control and code maintenance.\n\n### Main Functionalities\n\n1. **Docstring Management**: Ensures the presence of a standardized docstring header in Python files by checking for a specific tag.\n\n2. **Git Repository Management**: Checks if the specified directory is a Git repository and whether certain files within it have uncommitted changes. It provides functionalities to handle user confirmations when uncommitted changes are present.\n\n3. **File and Cache Operations**: Manages file retrieval and caching operations, including loading and saving cache information about the files.\n\n4. **File Integrity and Backup Management**: Computes SHA-256 hashes for files to check for changes and creates backups of files before modifications.\n\n5. **Differencing**: Displays differences between original and modified versions of code to facilitate code review processes.\n\n6. **Directory Traversal**: Facilitates directory navigation within the repository, categorizing folders based on their depth to aid in analysis or reporting.\n\n### Purpose\n\nThe purpose of this Python module can be summarized as follows:\n- To facilitate efficient management of Python files within a Git-controlled environment.\n- To enhance code maintenance practices through automated checks, docstring handling, change tracking, and backup creation.\n- To support developers in ensuring code quality and consistency by providing tools for version comparison and repository management.\n\n### Function Descriptions\n\nThe file comprises several well-defined functions:\n\n1. **ensure_docstring_header(content: str) -> str**:\n   - Ensures that the input string contains a docstring header, appending it if missing.\n   - **Args**: `content`: The content of the file.\n   - **Returns**: The modified content with the docstring header.\n   \n2. **file_has_uncommitted_changes(repo_path: str, file_path: str) -> bool**:\n   - Checks if the specified file has uncommitted changes using the `git diff` command.\n   - **Returns**: `True` if there are uncommitted changes, otherwise `False`.\n\n3. **prompt_user_confirmation(message: str) -> bool**:\n   - Prompts the user for confirmation and waits for \"yes\" or \"no\" responses.\n   - **Returns**: `True` if the user confirms, otherwise `False`.\n\n4. **check_git_repo(repo_path) -> bool**:\n   - Checks if the specified directory is a Git repository by executing a specific Git command.\n   - **Returns**: `True` if it's a Git repository, otherwise `False`.\n\n5. **has_uncommitted_changes(repo_path) -> bool**:\n   - Checks for any uncommitted changes in the whole repository and prompts the user for action if any are found.\n   - **Returns**: `True` if uncommitted changes are present, otherwise `False`.\n\n6. **load_cache(cache_file: str) -> Dict[str, str]**:\n   - Loads the cache from a specified JSON file into a dictionary.\n   - **Returns**: A dictionary mapping file paths to hash values or an empty dictionary if the file does not exist.\n\n7. **save_cache(cache_file: str, cache: Dict[str, str])**:\n   - Saves the cache dictionary into a JSON file.\n   - **Args**: `cache_file`: The filename for saving the cache data.\n\n8. **get_python_files(repo_path: str) -> List[str]**:\n   - Recursively retrieves all Python files in the specified repository.\n   - **Returns**: A list of file paths for all `.py` files found.\n\n9. **sort_files_by_size(file_paths: List[str]) -> List[str]**:\n   - Sorts given file paths in ascending order based on their file sizes.\n   - **Returns**: A list of file paths sorted by size.\n\n10. **compute_sha256(file_path: str) -> str**:\n    - Computes and returns the SHA-256 hash of the specified file.\n    - **Returns**: The computed hash as a hexadecimal string.\n\n11. **traverse_repo(repo_path: str, pr_depth: int) -> Dict[int, List[str]]**:\n    - Traverses the repository to categorize folders by their depth relative to the root.\n    - **Returns**: A dictionary mapping depth levels to lists of folder paths.\n\n12. **create_backup(file_path: str)**:\n    - Creates a backup of the specified file, appending a timestamp to the backup's filename.\n   \n13. **show_diff(original_code: str, modified_code: str) -> str**:\n    - Generates and returns a unified diff between two code string versions.\n    - **Returns**: A string representing the differences.\n\n### Structure and Intent\n\n- **Imports**: The file imports various modules that provide functionalities like file handling, Git commands, JSON management, logging, and time manipulation.\n\n- **Logging**: Throughout the functions, logging is used to output information or errors, which helps in debugging and tracking the application's behavior.\n\n- **Error Handling**: The functions expect various conditions (e.g., existence of files, status of Git repositories) and handle exceptions to ensure the application doesn\u2019t crash unexpectedly.\n\n### Conclusion\n\nIn summary, this Python module is a practical tool designed to enhance the management of Python code within Git repositories. Its functionalities cater to ensuring consistent coding practices, integrity checks through hashing, structured documentation via docstring headers, and the ability to efficiently back up changes. Through these features, the module aids developers in maintaining a clean, efficient workflow, contributing to improved code quality and easier project management."
  },
  {
    "file": "./docstring_ai/__main__.py",
    "description": "Here\u2019s a comprehensive and detailed description of the provided Python file, capturing its main functionalities, purpose, classes, and function constructors along with important context, structure, and intent.\n\n### Overview\n\nThis Python script automates the process of adding docstrings to Python files, integrating with GitHub to create pull requests (PRs) using OpenAI's API for generating the docstring content. It leverages various modules to handle command-line interface (CLI) interactions, file operations, environment variables, and GitHub API interactions.\n\n### Main Functionalities\n\n1. **Documenting Python Code**: The script automates the process of generating and adding docstrings to Python functions and classes based on code analysis and specified templates.\n\n2. **GitHub Integration**: It integrates with GitHub to facilitate the creation of pull requests for modified files, enabling version control and collaborative development.\n\n3. **API Interaction**: It interacts with OpenAI\u2019s API to generate meaningful docstring comments, enhancing the readability and maintainability of the code.\n\n4. **Command-Line Interface**: The script provides a CLI for users to specify input parameters such as paths, API keys, and repository details.\n\n5. **Error Handling and User Prompts**: It includes mechanisms for error handling, user confirmations, and checking conditions (like uncommitted changes) before proceeding with modifications.\n\n### Purpose\n\nThe purpose of this Python module can be summarized as follows:\n- To facilitate the documentation of Python codebases by automatically adding docstring headers to functions and classes.\n- To enhance collaboration by integrating the documentation process with GitHub, allowing developers to easily create pull requests for their changes.\n- To streamline code review and increase code quality through automated docstring generation.\n\n### Function Descriptions\n\nThe file includes several key functions aimed at accomplishing the defined tasks:\n\n1. **is_git_repo(folder_path)**:\n   - Determines if the specified folder is a Git repository using a `git` command.\n   - **Returns**: `True` if it is a repository, `False` otherwise.\n\n2. **get_remote_url(folder_path)**:\n   - Retrieves the remote URL for the Git repository.\n   - **Returns**: The remote URL as a string or `None` if it fails.\n\n3. **parse_github_url(remote_url)**:\n   - Extracts user and repository name from a GitHub remote URL.\n   - **Returns**: A tuple (user, repo).\n\n4. **determine_pr_target(path: str, args)**:\n   - Determines whether to enable PR creation and identifies the target GitHub repository.\n   - **Args**: Takes the repository path and parsed CLI arguments.\n   - **Returns**: A tuple indicating if PR creation is enabled and the GitHub repository string if applicable.\n\n5. **determine_target_branch(path: str, args)**:\n   - Determines the target branch for the PR based on the current Git branch or CLI arguments.\n   - **Returns**: The name of the target branch.\n\n6. **main()**:\n   - The primary entry point of the script. Sets up the CLI, validates arguments, and orchestrates the process of adding docstrings and integrating with GitHub.\n   - **Handles**:\n     - Argument parsing for user inputs.\n     - PR target and branch determination.\n     - Cleaning up caches if the `--no-cache` flag is used.\n     - Executes the process_files_and_create_prs function to handle file processing and GitHub integration.\n\n### Structure and Intent\n\n- **Imports**: The script imports relevant libraries for various functionalities such as handling GitHub interactions, command-line argument parsing, file I/O operations, and environmental variable management.\n\n- **Logging**: The script maintains logging for tracking execution steps, informing users of actions taken, and logging any errors encountered during execution.\n\n- **Setup and Configuration**: It utilizes environment variables loaded from a `.env` file for sensitive information like API keys, contributing to better security practices.\n\n- **User Prompts**: The script engages users through prompts, ensuring that critical actions (like proceeding with changes) are confirmed, thus reducing the risk of unintended modifications.\n\n### Conclusion\n\nIn summary, this Python module is a comprehensive and automated tool designed to streamline the process of documenting Python codebases by adding docstrings and integrating these modifications with GitHub through pull requests. It enhances the developer experience by combining functionalities for code documentation, version control, and user interaction in a single automated workflow. This results in improved code quality and easier collaboration in software development projects, significantly aiding developers in maintaining and documenting their Python projects efficiently."
  },
  {
    "file": "./docstring_ai/lib/docstring_utils.py",
    "description": "Here\u2019s a comprehensive and detailed description of the provided Python file, capturing its functionalities, purpose, classes, and function constructors, as well as important context and intent.\n\n### Overview\n\nThis Python module is designed to facilitate the extraction and manipulation of docstrings from Python code. The module includes functions for parsing Python classes, extracting descriptions from docstrings, adding docstrings through the OpenAI API, and logging errors that may arise during execution. It utilizes the Abstract Syntax Tree (AST) to analyze Python code structure and content, significantly enhancing code documentation practices.\n\n### Main Functionalities\n\n1. **Docstring Extraction**: Functions to extract and compile descriptions from docstrings present in functions, classes, and modules.\n\n2. **Class Parsing**: Ability to parse Python files to identify classes and their parent classes, allowing for better organization and understanding of class hierarchies.\n\n3. **Logging Mechanism**: Integrated logging for debugging and error reporting purposes, which helps in tracking the status of operations and identifying failures.\n\n4. **AST Utilization**: Utilizes Python's AST library to analyze code structure, offering a programmatic way to traverse and manipulate Python code.\n\n5. **OpenAI API Interaction**: Although not displayed in the current functions, it has integrations indicative of future capabilities for enhancing docstring content with AI-generated suggestions through OpenAI's Assistant.\n\n### Purpose\n\nThe purpose of this module can be summarized as follows:\n- To automate the documentation process in Python codebases by extracting existing docstrings and ensuring proper documentation standards.\n- To provide utilities for better understanding the structure of Python code, especially regarding classes and their relationships.\n- To streamline the interaction between developers and OpenAI's Assistant for enhancing docstring content dynamically as needed.\n\n### Function Descriptions\n\nThe file contains several well-defined functions aimed at achieving the aforementioned purposes:\n\n1. **extract_description_from_docstrings(code_with_docstrings: str) -> str**:\n   - Parses provided Python code and extracts the first line of docstrings, returning them as a semicolon-separated string.\n   - **Args**: `code_with_docstrings`: The Python code containing docstrings.\n   - **Returns**: A string of extracted descriptions.\n   - **Raises**: Exception if there are errors during parsing.\n\n2. **extract_class_docstring(code: str, class_name: str) -> str**:\n   - Extracts the docstring of a specified class from the provided Python code.\n   - **Args**: `code`: The code containing class definitions; `class_name`: The target class name.\n   - **Returns**: The class docstring or an empty string if not found.\n   - **Raises**: Exception for errors encountered during extraction.\n\n3. **parse_classes(file_path: str) -> Dict[str, List[str]]**:\n   - Reads and parses a Python file to construct a dictionary mapping class names to their parent classes.\n   - **Args**: `file_path`: Path to the Python file to analyze.\n   - **Returns**: A dictionary of classes and their parent classes.\n   - **Raises**: Exception for errors during reading or parsing.\n\n### Class: DocstringExtractor\n\nThe module defines the `DocstringExtractor` class, which encapsulates methods for extracting docstrings and analyzing Python files.\n\n#### Class Description\n\n```python\nclass DocstringExtractor:\n    \"\"\"\n    A class to extract all docstrings from a Python file and compile them into a readable format.\n    \"\"\"\n\n    def __init__(self, file_path: str):\n        \"\"\"\n        Initializes the extractor with the path to the Python file.\n\n        Args:\n            file_path (str): The path to the Python script to be analyzed.\n        \"\"\"\n        self.file_path = file_path\n        self.file_content: Optional[str] = None\n        self.tree: Optional[ast.AST] = None\n        self.docstrings: Dict[str, Dict[str, str]] = {}\n        self.imports: Dict[str, List[str]] = {}\n```\n\n#### Constructor\n\n- **`__init__`**: Initializes the `DocstringExtractor` with the path to the Python file, setting up attributes for file content, AST tree, docstrings, and imports.\n\n#### Key Methods\n\n1. **read_file() -> None**:\n   - Reads the content of the specified Python file into memory.\n   - **Raises**: FileNotFoundError and IOError for issues during file access.\n\n2. **parse_ast() -> None**:\n   - Parses the read file content into an Abstract Syntax Tree (AST).\n   - **Raises**: SyntaxError if the code has invalid syntax, and ValueError if the file content is not set.\n\n3. **extract_docstrings() -> None**:\n   - Extracts docstrings from the AST and populates the `docstrings` dictionary.\n   - Gathers module-level docstring and those associated with classes and functions.\n\n4. **list_imports_from_package(package: str) -> List[str]**:\n   - Scans the AST for imports from a specified package.\n   - **Args**: `package`: The package to extract imports from.\n   - **Raises**: ValueError if the AST hasn't been parsed.\n\n5. **compile() -> str**:\n   - Combines the extracted docstrings into a reader-friendly text format.\n   - **Returns**: String that summarizes the docstrings.\n\n6. **get_docstrings_dict() -> Dict[str, Dict[str, str]]**:\n   - Returns the dictionary of extracted docstrings.\n\n7. **process() -> Dict[str, Dict[str, str]]**:\n   - High-level function that handles the entire process of reading the file, parsing the AST, and extracting docstrings.\n   - **Returns**: The dictionary of extracted docstrings.\n\n8. **process_imports(package: str) -> List[str]**:\n   - High-level method to list all imports for a specified package.\n   - **Args**: `package`: The target package for import extraction.\n   \n### Logging Configuration\n\n- The module utilizes Python\u2019s built-in logging module to track execution through logging statements at different levels, including `info`, `warning`, and `error`, ensuring developers can debug effectively.\n\n### Conclusion\n\nIn summary, this file provides a robust framework for automating docstring extraction and management in Python code. Through the use of AST for code analysis, the module not only enhances documentation practices but also consolidates knowledge about Python class structures. The integration with OpenAI\u2019s API indicates potential future features aimed at enriching the generated docstrings, thus streamlining the documentation process even further. This module is invaluable for projects where consistent documentation is essential for maintenance and readability."
  },
  {
    "file": "./docstring_ai/lib/github_utils.py",
    "description": "Here's a comprehensive and detailed description of the provided Python file, emphasizing its main functionalities, purpose, classes, function constructors, and important details that help understand the intent and structure of the code.\n\n### Overview\n\nThis Python module provides functionality for integrating with the GitHub API to automate the process of creating pull requests (PRs). Specifically, it focuses on managing branches, committing changes, and generating pull requests that incorporate modifications made to Python files in a local Git repository. It utilizes a number of libraries for handling file operations, Git repository interactions, and logging.\n\n### Main Functionalities\n\n1. **Branch Management**: Functions to sanitize branch names, create and switch branches, and check out specified branches.\n\n2. **Change Detection**: Ability to retrieve a list of changed Python files between branches for inclusion in PRs.\n\n3. **GitHub Integration**: Automates the tasks of interacting with the GitHub API, including creating pull requests, making commits, and pushing changes to remote repositories.\n\n4. **File Handling**: Functions to traverse directories and collect relevant files (Python files in this case).\n\n5. **Logging**: Integrated logging functionality to provide detailed output on operations, successes, and errors encountered during execution.\n\n### Purpose\n\nThe primary purpose of this module can be summarized as:\n- To facilitate the automation of committing and pushing changes to a GitHub repository, including the generation of pull requests for modifications made by developers. This streamlines workflow in collaborative development environments by reducing manual operations and ensuring consistency in version control tasks.\n\n### Function Descriptions\n\nThe file contains several key functions aimed at accomplishing these tasks:\n\n1. **sanitize_branch_name(name: str) -> str**:\n   - Sanitizes and formats a branch name by replacing invalid characters with underscores and flattening any hierarchy by replacing slashes with dashes.\n   - **Returns**: A sanitized string for the branch name.\n\n2. **generate_unique_suffix() -> str**:\n   - Generates a unique suffix (8 characters) using UUID4 for branch naming.\n   - **Returns**: A unique string suffix.\n\n3. **create_github_pr(repo_path: str, github_token: str, github_repo: str, branch_base_name: str, pr_name: str, target_branch: str) -> bool**:\n   - Automates the creation of a GitHub pull request, including committing changes and pushing them to a new branch on GitHub.\n   - This function handles:\n     - Branch creation\n     - Changes commit and push\n     - Pull request creation with details of changed files.\n   - **Returns**: True if the PR was created successfully, otherwise False.\n\n4. **checkout_branch(repo_path: str, branch_name: str) -> bool**:\n   - Checks out the specified branch in a local Git repository.\n   - **Returns**: True if the checkout was successful, otherwise False.\n\n5. **get_python_files(repo_path: str) -> List[str]**:\n   - Retrieves and returns a list of all Python files within the specified repository directory.\n   - **Returns**: A list of strings, each representing the path to a Python file.\n\n6. **create_pull_request_body(changed_files: List[str]) -> str**:\n   - Constructs the body content for the pull request, listing the changed Python files.\n   - **Returns**: A string formatted for the pull request description.\n\n7. **commit_and_push_changes(repo_path: str, branch_name: str, commit_message: str) -> bool**:\n   - Manages Git operations to add changes, commit them, and push to a specified branch.\n   - **Returns**: True if the operations are successful, otherwise False.\n\n8. **get_changed_files(repo_path: str, branch_name: str, base_branch: str) -> List[str]**:\n   - Retrieves all changed Python files between the provided feature branch and base branch.\n   - **Returns**: A list of paths to changed Python files.\n\n9. **log_git_status(repo_path: str) -> bool**:\n   - Logs the current Git status of the repository.\n   - **Returns**: True if the status was logged successfully, otherwise False.\n\n### Structure and Context\n\n- **Imports**: The module imports various libraries required for file handling, Git operations, logging, and managing GitHub interactions. The use of libraries such as `os`, `argparse`, and `subprocess` plays a crucial role in command execution and filesystem manipulation.\n\n- **Logging Setup**: Throughout the module, logging is standardized to capture information at various steps, aiding in debugging and operational oversight.\n\n- **Error Handling**: The module contains comprehensive error handling, especially around Git operations, ensuring that any failures during branch checks, commits, and pushes are logged and handled appropriately.\n\n### Conclusion\n\nIn summary, this Python module is designed to streamline the process of managing pull requests in a GitHub repository by automating branch creation, file change detection, committing, and PR generation. It greatly simplifies a developer's workflow in collaborative environments by reducing the need for manual git operations and ensuring consistent PR processes. With proper logging and error management, the module provides a robust solution for integrating code changes with GitHub efficiently."
  },
  {
    "file": "./docstring_ai/lib/prompt_utils.py",
    "description": "Here's a comprehensive and detailed description of the provided Python file, emphasizing its main functionalities, purpose, classes, function constructors, and important contextual information.\n\n### Overview\n\nThis Python module facilitates the operation of an AI assistant specifically designed to generate and add docstrings to Python code. It leverages OpenAI's services to create and manage an assistant, handle prompts, and interact with code context stored in ChromaDB. The module includes utilities for managing threads of interaction, constructing few-shot prompts for effective AI responses, and updating the assistant's resources.\n\n### Main Functionalities\n\n1. **Assistant Management**: Functions to initialize, retrieve, and manage the assistant that operates based on OpenAI\u2019s API, ensuring it is set up to handle requests for adding docstrings.\n\n2. **Prompt Construction**: Capability to create prompts using existing context data and few-shot examples to generate quality responses from the AI assistant.\n\n3. **Thread Management**: Functions for creating threads to maintain conversation contexts with the assistant, enabling ongoing exchanges without losing context.\n\n4. **File Handling**: Use of ChromaDB to retrieve relevant context about Python code, and operations to generate and manage docstrings effectively.\n\n5. **Error Handling and Logging**: Integrated logging for debugging and tracing the execution flow; it captures errors or misconfigurations that might arise during API interactions.\n\n### Purpose\n\nThe purpose of this module can be summarized as follows:\n- To automate the process of enhancing Python code documentation through the use of an AI assistant that generates comprehensive and context-aware docstrings.\n- To manage interactions with OpenAI\u2019s API and ChromaDB to ensure that the context and content generated are relevant and tailored to the specific needs of the code being documented.\n- To streamline workflows for developers, enabling them to focus on core coding tasks while automatically improving documentation quality.\n\n### Class Description\n\n#### `PythonFile`\n\n```python\nclass PythonFile(BaseModel):\n    new_file_content: str = Field(description=\"Updated python script with the updated docstrings.\")\n```\n- **Purpose**: This class, defined using Pydantic's `BaseModel`, is designed to manage the file content for a Python script that has been updated to include new docstrings.  \n- **Attributes**:\n  - `new_file_content`: A string that holds the content of the updated Python script after the docstrings have been added.\n\n### Function Descriptions\n\nThe file includes several key functions aimed at achieving its goals:\n\n1. **initialize_assistant(api_key: str, assistant_name: str = \"DocstringAssistant\") -> str**:\n   - Initializes or retrieves an existing AI assistant.\n   - **Returns**: The ID of the assistant or `None` if an error occurs.\n\n2. **update_assistant_tool_resources(api_key: str, assistant_id: str, file_ids: List[str]) -> None**:\n   - Updates the assistant\u2019s resources with new file IDs, creating a vector store.\n   - **Raises**: Exception for errors updating resources.\n\n3. **create_thread(api_key: str, assistant_id: str, initial_messages: List[dict] = None) -> str**:\n   - Creates a new thread for communicating with the assistant.\n   - **Returns**: The ID of the created thread or `None` if an error occurs.\n\n4. **construct_few_shot_prompt(collection: chromadb.Collection, classes: Dict[str, List[str]], max_tokens: int, context: str = None) -> str**:\n   - Constructs a few-shot prompt using context summaries.\n   - **Returns**: A formatted string prompt for the assistant.\n\n5. **extract_code_from_message(message: str) -> str**:\n   - Extracts code blocks from the assistant's messages using a regular expression.\n   - **Returns**: The extracted code block or raises an error if none exists.\n\n6. **send_message_to_assistant(assistant_id: str, thread_id: str, prompt: str, response_format: BaseModel = None, tools: List = [], tool_choice=\"auto\", functions: Dict[str, Callable] = {}) -> str**:\n   - Sends a message to the assistant and retrieves a response.\n   - **Returns**: The assistant's response text or an error message if an issue occurs.\n\n7. **generate_file_description(assistant_id: str, thread_id: str, file_content: str) -> str**:\n   - Generates a detailed description of a Python file using the assistant.\n   - **Returns**: A string containing the file description.\n\n8. **create_file_with_docstring(assistant_id: str, thread_id: str, code: str, context: str, functions: Dict[str, Callable]) -> str**:\n   - Requests the assistant to add docstrings to the provided code.\n   - **Returns**: The code with added docstrings, or `None` if an error occurs.\n\n9. **create_vector_store(vector_store_name: str, file_ids: List[str]) -> str**:\n   - Creates a vector store in ChromaDB and associates it with file IDs.\n   - **Returns**: The ID of the created vector store.\n\n10. **poll_run_completion(run_id: str, thread_id: str, functions: Dict[str, Callable]) -> bool**:\n    - Polls until the completion of a run, implementing a retry mechanism.\n    - **Returns**: `True` if successful; otherwise, `False`.\n\n11. **retrieve_last_assistant_message(thread_id: str) -> str**:\n    - Retrieves the last message from a thread to maintain context in conversations.\n    - **Returns**: The last message text or `None` if no messages exist.\n\n### Context and Structure\n\n- **Imports**: The module imports numerous libraries to handle API interactions, logging, data manipulation, and type-checking with Pydantic.\n\n- **Error Handling**: Extensive error handling incorporates logging statements to provide insights into possible failures during execution, making it easier to debug.\n\n- **Prompt Management**: The use of few-shot prompting demonstrates an innovative way to generate high-quality responses from AI, leveraging prior examples to guide the assistant\u2019s output.\n\n### Conclusion\n\nIn summary, this Python module serves as a powerful tool for automating the documentation of Python projects through the interaction of an AI assistant with developers. By integrating OpenAI\u2019s API and managing data contexts from ChromaDB, the module streamlines the process of adding comprehensive docstrings to Python code. Its design emphasizes usability through structured functions, effective error handling, and a logging system that captures crucial information about actions taken and any issues encountered. This tool is invaluable for enhancing code quality and ensuring that documentation is clear and informative."
  },
  {
    "file": "./docstring_ai/lib/process.py",
    "description": "Here's a comprehensive and detailed description of the provided Python file, focusing on its main functionalities, purpose, classes, function constructors, and other relevant contextual information.\n\n### Overview\n\nThis Python module automates the process of enhancing Python code documentation by generating and adding docstrings using OpenAI's Assistant. It further integrates with ChromaDB for contextual keyword storage and GitHub for creating pull requests. The file includes several functions for file processing, API communication, update management, and documentation generation.\n\n### Main Functionalities\n\n1. **Docstring Addition**: The module uses OpenAI's API to generate docstrings based on the context of existing Python code.\n\n2. **GitHub Integration**: It facilitates the creation of pull requests on GitHub after processing Python files, allowing for collaboration and version control.\n\n3. **Context Management**: The module utilizes ChromaDB to embed and retrieve contextual information related to the code being processed, aiming to generate accurate and informative docstrings.\n\n4. **File Management**: The module can traverse directories to find Python files, verify their unique identifiers through SHA-256 hashes, and manage file updates and backups.\n\n5. **Progress Tracking**: Incorporates visualization libraries like `tqdm` to show progress updates during file processing, improving user experience during long-running tasks.\n\n### Purpose\n\nThe primary purpose of this module is to provide an automated system for enhancing the documentation quality of Python codebases by adding comprehensive docstrings through the assistant's interactions with the code. This reduces the manual workload for developers while maintaining or improving code quality and documentation standards. Additionally, the integration with GitHub allows for seamless collaboration.\n\n### Function Descriptions\n\nThe file consists of several key functions outlined below:\n\n1. **process_files_and_create_prs(repo_path: str, api_key: str, create_pr: bool, github_token: str, github_repo: str, branch_name: str, pr_name: str, pr_depth: int, manual: bool, target_branch: str) -> None**:\n   - Processes Python files, adds docstrings, and creates pull requests on GitHub if specified.\n   - **Args**: Paths, API keys, and PR specifications.\n   - **Raises**: Various exceptions during processing, logged appropriately.\n\n2. **process_single_file(python_file_path: str, repo_path: str, assistant_id: str, thread_id: str, collection, context_summary: list, cache: dict, manual: bool) -> None**:\n   - Processes a single Python file to generate and add docstrings.\n   - Handles reading, modifying, and saving files, as well as manual approval and context updates.\n\n3. **filter_files_by_hash(file_paths: List[str], repo_path: str, cache: Dict[str, str]) -> List[str]**:\n   - Filters files based on their SHA-256 hash to determine which files need processing.\n   - **Returns**: List of files to be processed.\n\n4. **upload_files_to_openai(file_paths: List[str]) -> List[str]**:\n   - Uploads Python files to OpenAI for further processing and returns their file IDs.\n   - **Returns**: List of file IDs uploaded.\n\n5. **create_github_pr(...)**:\n   - Creates a pull request on GitHub incorporating changes made to files.\n\n6. **get_python_files(repo_path: str) -> List[str]**:\n   - Retrieves a list of all Python files in the specified directory.\n   - **Returns**: List of relative paths of Python files.\n\n7. **create_pull_request_body(changed_files: List[str]) -> str**:\n   - Creates the body content for the pull request, listing all modified files.\n\n### Contextual Information\n\n- **Imports**: The module imports needed libraries such as `openai`, `chromadb`, and `tqdm` for API interactions and progress tracking, and standard libraries like `os`, `json`, and `logging` for general operations.\n\n- **Logging**: The module uses the `logging` library extensively for debugging and tracking errors, which aids in maintaining clear operation traces throughout the processing.\n\n- **Caching**: The implementation includes caching mechanisms to track file states across runs, reducing unnecessary processing on files that have not changed.\n\n- **Error Handling**: Each function is equipped with error handling that logs issues encountered during execution, which is crucial for debugging and maintaining the module.\n\n### Structure\n\nThe structure of the module is organized around the main processing function, `process_files_and_create_prs`, which orchestrates the overall workflow, making it easy to understand and maintain. Helper functions are succinctly defined to handle file management and GitHub-related operations, maintaining a modular design.\n\n### Conclusion\n\nIn summary, this Python module plays a critical role in automating the generation of docstrings for Python files, utilizing OpenAI's capabilities in a structured workflow. By integrating with ChromaDB for context retrieval and facilitating easy GitHub pull request creation, it streamlines the documentation process in software development. The careful implementation of error handling, caching, and logging enhances its reliability and effectiveness in real-world usage. This module is particularly valuable for teams aiming to maintain high standards in documentation and code quality while minimizing manual effort."
  }
]